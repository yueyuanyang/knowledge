### 细说中文分词

完整的中文自然语言处理过程一般包括以下五种中文处理核心技术：分词、词性标注、命名实体识别、依存句法分析、语义分析。其中，分词是中文自然语言处理的基础，搜素引擎、文本挖掘、机器翻译、关键词提取、自动摘要生成等等技术都会用到中文分词，包括最近在学习的聊天机器人、文本相似性等。可以说分词是自然语言大厦的地基，下面就让我们从它开始谈起。

#### 什么是中文分词
中文分词就是将中文语句中的词汇按照使用时的含义切分出来的过程，也就是将一个汉字序列切分成一个个有单独含义的词语。自20世纪80年代以来，中文自动分词就一直是一个研究热点，由于中文语言的复杂性使之一直处于发展阶段。目前，分词主要包含细粒度分词和粗粒度分词两种，在不同的应用场景需要用到不同的粒度。细粒度分词是指将原始语句切分成最基本的词语，而粗粒度分词是指将原始语句中的多个基本词组合起来切成一个词，进而组成语义相对明确的实体。

- 原始串：浙江大学坐落在西湖旁边
- 细粒度：浙江/大学/坐落/在/西湖/旁边
- 粗粒度：浙江大学/坐落/在/西湖/旁边

#### 为什么要中文分词
对于中文而言，词是承载语义的最小单元，由词构成语句，又由语句构成篇章。但是，中文文本是由连续的字序列构成，词与词之间是没有天然的分隔符。在自然语言处理领域，国外已经做出了很多卓有成效的研究，但是那些研究大多基于英文（存在天然的分隔符），也就是说是以正确切分出单词为前提的。于是，NLP对于中文而言要想取得较好的科研成果，就需要准确识别词与词之间的边界，也就是分词。

接下来我们就以搜索为例，具体的阐述一下分词的重要性与必要性。大家都知道，目前的搜素引擎是基于一种叫做倒排索引的结构，以什么作为索引的key值，直接影响到整个搜索引擎的准确度、召回率以及性能。

如果不使用中文分词，可以采用单个汉字索引方式。例如“标点符”，会先索引“标”字，再索引“点”字，再索引“符”字。搜索过程中，也是先寻找“标”字关联的所有文档，再寻找“点”字关联的所有文档，再寻找“符”字关联的所有文档，最后对所有被检索出的文档做“与”运算，同时“标点符”位置连续的文档才算符合要求。这种方式存在一个非常挑战性的问题，常用汉字总共3000左右，每次查询过程中进行“与”操作的计算量会相当大。对于大数据量的搜索引擎来讲，每天面临亿万级别的查询，这样的索引结构无疑是灾难性的。

为了优化上面提到的速度问题，还有另外一种索引结构也是可以避开中文分词的，那就是n元组合索引方式。用2元索引来说，“标点符”，会先索引“标点”，再索引“点符”。在搜索过程中，也是对“标点”和“点符”检索出的文章进行“与”运算。这样的搜索过程会大大减少在搜索过程中的计算量，但是仍会面临另外一个问题：准确度。有很多这样的例子，搜“北大”会检索出“东北大学”，搜“的士”会出现“不想当将军的士兵不是好士兵”。对于大数据量的搜索引擎系统来说，这样的用户体验是极差的。

#### 中文分词面临的挑战
在知道分词的重要性之后，那么我们会面临一个新的问题，如何才能把一个字序列准确的切分成词序列，就像下面的例子会有不止一种的切分方式。

原始字符串：结婚的和尚未结婚的

- 切分一：结婚/的/和尚/未/结婚/的
- 切分二：结婚/的/和/尚未/结婚/的
还有更极端的例子，“中外科学名著”中，“中外”、“外科”、科学”、“学名”、“名著”都是合理的词语。类似的例子数不胜数，“提高产品质量”，“鞭炮声响彻夜空”。在中文分词的世界里，最主要的挑战有两个：歧义词识别，未登录词识别。

#### 歧义词
上文提到的歧义词例子，有学者试图通过逆向匹配来解决。但是，碰到这句“结合成分子”时，采用逆向匹配，则会分成“结合/成分/子时”。一般当一个字可以同时作为两个词的组成部分，当这两个词按序同时出现时，就可能会出现歧义现象。目前的歧义一般分为三种：交叉歧义，组合歧义，真歧义。

交叉歧义（字符串AJB，AJ和JB都是一个汉语词汇，会存在多种切分交叉在一起）：“你说的确实在理”，“的确”和“确实”就是交叉型歧义片段。
组合歧义（字符串AB是一个词汇，A和B同时也是词汇，会存在不同语义下切分不同）：“这个人手上有颗痣”，“目前人手紧缺”。前者是“人”/“手”两个实体词，后者是“人手”一个实体词。
真歧义（怎么切分都合理）：“乒乓球拍卖完了”，切分为以下两种情况都是合理的，“乒乓球拍/卖/完了”，“乒乓球/拍卖/完了”。
#### 未登录词
所谓的未登录词是指在分词词典中没有收录，并且确实是大家公认的词语的那些词语，一般又叫做新词。最典型的未登录词就是人名词，“李胜利喜欢唱歌”中“李胜利”是个人名词，如果把“李胜利”这个基本词条收录到字典中去是能解决这个问题。但是，每时每刻都有新增的姓名，完整收录全部人名本身就是一个不现实的工程。中外人名、中国地名、机构组织名、事件名、货币名、缩略语、派生词、各种专业术语以及在不断发展和约定俗成的一些新词语。在当下的互联网时代，人们还会不断的创造出一些新词出来，比如：“神马”、“不明觉厉”等。未登录词辨别未登录词包括是种类繁多，形态组合各异，规模宏大的一个领域。对这些词语的自动辨识，是一件非常困难的事。

新词是中文分词算法在召回层面上最主要的难题，也是评价一个分词系统好坏的重要标志。如果一个新词无法被分词系统识别，会导致很多噪音数据被召回，进而会影响后面的句法分析和语义分析等相关处理。黄昌宁等在中文信息学报上的《中文分词十年回顾》一文指出：新词带来的分词问题是歧义的10倍~20倍，所以说新词发现是分词面临的最大挑战。



