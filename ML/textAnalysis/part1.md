## 文本分析 —— 基于CHI/TFIDT/贝叶斯方法的网页分类器

**梳理思路**

- 第一步是下载搜狗的新闻分类[训练数据集](http://www.sogou.com/labs/resource/cs.php)
- 第二步是使用结巴中文分词工具对文本进行处理，并去停用词得到所有文本中出现的词语。
- 第三步是使用CHI作为特征选择的依据给每一类新闻选出150维的特征，并去重。这样我们就可以获得大概1000维的特征。
- 第四步有了特征之后就是为每个新闻构造VSM模型，即使用TFIDF方法计算各特征的权重得到表示该文本的特征向量。这样一来，我们就将原本的新闻文章转化成了（1000维特征向量， 新闻分类）这种可以方便使用KNN/SVM等方法分类的数据。
- 第五步接下来就是使用相应的分类器做分类，检查分类效果。主要参考了这片博客，并基于此进行修改加上了CHI/TFIDF的功能。 
