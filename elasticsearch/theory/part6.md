## ES 分片详解

**分片**

分片是一个底层的 工作单元，一个分片是一个 Lucene 的实例，它本身就是一个完整的搜索引擎,文档不会跨分片存储。

**索引与分片的关系图：**

![索引与分片的关系图](https://github.com/yueyuanyang/knowledge/blob/master/elasticsearch/img/15050012808218.jpg)

**存储目录截图：**

![存储目录截图：](https://github.com/yueyuanyang/knowledge/blob/master/elasticsearch/img/15050013393691.jpg)

一个分片可以是 `主分片`或者 `副本分片`，索引建立的时候就已经确定了主分片数，副本分片数可以随时修改。

初始化时确定主分片数：
依据硬件情况等定好单个分片容量，依据业务场景预估数据量和增长量，除以单个分片容量。
分片数不够时，可以考虑重建索引，或者使用一个新的索引名称。搜索 1 个有着 50 个分片的索引与搜索 50 个每个都有 1 个分片的索引完全等价。


### 索引别名

索引 别名 就像一个快捷方式或软连接，可以指向一个或多个索引。可以用于实现索引分组，或者索引间的无缝切换

### 动态更新索引

倒排索引(Lucene中的段)被写入磁盘后是 不可改变 的:它永远不会修改
es增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到—从最早的开始–查询完后再对结果进行合并

### 近实时搜索

按段（per-segment）搜索的发展
新段会被先写入到文件系统缓存，稍后再被刷新到磁盘，只要文件已经在缓存中， 就可以像其它文件一样被打开和读取了。

### 持久化变更

每一次对 Elasticsearch 进行操作时均记录事务日志，当 Elasticsearch 启动的时候，并且会重放 translog 中所有在最后一次提交后发生的变更操作。

### 段合并

为节省资源，提高检索效率，Elasticsearch通过在后台进行段合并，小的段被合并到大的段，然后这些大的段再被合并到更大的段。
通过optimize API可以将一个分片强制合并到指定的段数目。 （通常减少到一个）。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化

## 分布式存储 —— 文档存储到哪个分片？

**路由文档到分片**

```
shard = hash(routing) % number_of_primary_shards
```

其中： routing 默认是文档ID，这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数的范围永远是0到number_of_primary_shards - 1，这个数字就是特定文档所在的分片。**这也解释了为什么主分片的数量只能在创建索引时定义且不能修改：如果主分片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。**

通常情况下，ElasticSearch是如何把数据分发到各个分片中，哪个分片存储哪一类的文档等细节并不重要。因为查询时，将查询命令分发到每个分片 就OK了。唯一的关键点在于算法，将数据均等地分配到各个分片的算法。在删除或者更新文档时，情况就会变得有点复杂了。实际上，这也不是什么大问题。只要 保证分片算法在处理文档时，对于相同的文档标识生成相同的映射值就可以了。如果我们有这样的分片算法，ElasticSearch就知道在处理文档时，如 何定位到正确的分片。但是，在选择文档的存储分片时，采用一个更加智能的办法不就更省事儿了吗？比如，把某一特定类型的书籍存储到特定的分片上去，这样在 搜索这一类书籍的时候就可以避免搜索其它的分片，也就避免了多个分片搜索结果的合并。这就是路由功能(routing)的用武之地。路由功能向 ElasticSearch提供一种信息来决定哪些分片用于存储和查询。同一个路由值将映射到同一个分片。这基本上就是在说：“通过使用用户提供的路由值，就可以做到定向存储，定向搜索。”

假设你有一个100个分片的索引。当一个请求在集群上执行时会发生什么呢？

- 1. 这个搜索的请求会被发送到一个节点

- 2. 接收到这个请求的节点，将这个查询广播到这个索引的每个分片上（可能是主分片，也可能是复制分片）

- 3. 每个分片执行这个搜索查询并返回结果

- 4. 结果在通道节点上合并、排序并返回给用户

因为默认情况下，Elasticsearch使用文档的ID（类似于关系数据库中的自增ID，当然，如果不指定ID的 话，Elasticsearch使用的是随机值）将文档平均的分布于所有的分片上，这导致了Elasticsearch不能确定文档的位置，所以它必须将 这个请求广播到所有的100个分片上去执行。这同时也解释了为什么主分片的数量在索引创建的时候是固定下来的，并且永远不能改变。因为如果分片的数量改变 了，所有先前的路由值就会变成非法了，文档相当于丢失了。

原来的查询语句：“请告诉我，USER1的文档数量一共有多少”

使用自定义Routing（在USESR　ID上）后的查询语句：“请告诉我，USER1的文档数量一共有多少，它就在第三个分片上，其它的分片就不要去扫描了”

**由于上面的路由规则，主分片数量不可变**

### 指定个性化路由

所有的文档API（get，index，delete，update和mget）都能接收一个routing参数，可以用来形成个性化文档分片映射。一个个性化的routing值可以确保相关的文档存储到同样的分片上——比如，所有属于同一个用户的文档。

**第一种方法**，也是比较直观的方法就是直接在请求的URL中指定routing参数：
```
  curl -XPOST 'http://localhost:9200/store/order?routing=user123' -d '  
    {  
        "productName": "sample",  
        "customerID": "user123"  
    }' 
```
这样我们就按照用户的customerID的值将具有相同customerID的文档置于同一分片上了。

**第二种方法**就是直接从文档中提取到对应的路由值：

```
 curl -XPUT 'http://localhost:9200/store/order/_mapping' -d '  
    {  
        "order": {  
            "_routing": {  
                "required": true,  
                "path": "customerID"  
            }  
        }  
    }'  
```

这样的方法和第一种方法在效果上一样的，但是有一点需要注意，相比于第一种方法这种方法的效率稍低，因为第一种方法直接就在请求的参数中确定了路由的值，而第二种方法中，首先需要将文档读入之后，再从中提取到对应的路由值。

### 利用路由机制的查询

```
    curl -XGET 'http://localhost:9200/store/order/_search?routing=user123' -d '  
    {  
        "query": {  
            "filtered": {  
                "query": {  
                    "match_all": {}  
                },  
                "filter": {  
                    "term": {  
                        "userID": "user123"  
                    }  
                }  
            }  
        }  
    }'
```

**单个写操作（Creating, indexing, or deleting）**

数据写到主分片。默认情况下，`主分片` 需要 规定数量在写入操作时可用。这是为了防止将数据写入到网络分区的 `背面`。

规定的数量定义公式如下：

```
quroum = int((primary + number_of_replicas) / 2 ) + 1
```






